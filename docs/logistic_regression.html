<!--
=========================================================
* * Black Dashboard - v1.0.1
=========================================================

* Product Page: https://www.creative-tim.com/product/black-dashboard
* Copyright 2019 Creative Tim (https://www.creative-tim.com)


* Coded by Creative Tim

=========================================================

* The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
-->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="apple-touch-icon" sizes="76x76" href="./assets/img/apple-icon.png">
  <link rel="icon" type="image/png" href="./assets/img/favicon.png">
  <title>
    European Hotel Analysis
  </title>
  <!--     Fonts and icons     -->
  <link href="https://fonts.googleapis.com/css?family=Poppins:200,300,400,600,700,800" rel="stylesheet" />
  <link href="https://use.fontawesome.com/releases/v5.0.6/css/all.css" rel="stylesheet">
  <!-- Nucleo Icons -->
  <link href="./assets/css/nucleo-icons.css" rel="stylesheet" />
  <!-- CSS Files -->
  <link href="./assets/css/black-dashboard.css?v=1.0.0" rel="stylesheet" />
</head>

<body class="">
  <div class="wrapper">
    <div class="sidebar">
      <div class="sidebar-wrapper">
        <div class="logo">
          <a href="javascript:void(0)" class="simple-text logo-mini">
            EHA
          </a>
          <a href="javascript:void(0)" class="simple-text logo-normal">
            Hotel Analysis
          </a>
        </div>
        <ul class="nav" style="list-style-type: none">
          <li>
            <a href="./index.html">
              <i class="tim-icons icon-world"></i>
              <p>Home</p>
            </a>
          </li>
          <li>
            <a href="./dashboard.html">
              <i class="tim-icons icon-chart-pie-36"></i>
              <p>Dashboard</p>
            </a>
          </li>
          <li>
            <a href="./machine_learning.html">
              <i class="tim-icons icon-atom"></i>
              <p>Machine Learning</p>
            </a>
          </li>
          <li>
            <a href="./data_preprocessing.html">
              <i class="tim-icons icon-align-left-2"></i>
              <p>Data Preprocessing</p>
            </a>
          </li>
          <li>
            <a href="./database.html">
              <i class="tim-icons icon-vector"></i>
              <p>Database</p>
            </a>
          </li>
          <li>
            <a href="./documentation.html">
              <i class="tim-icons icon-single-copy-04"></i>
              <p>Documentation</p>
          </li>    
        </ul>
      </div>
    </div>
    <div class="main-panel">
      <!-- Navbar -->
      <nav class="navbar navbar-expand-lg navbar-absolute navbar-transparent">
        <div class="container-fluid">
          <div class="navbar-wrapper">
            <div class="navbar-toggle d-inline">
              <button type="button" class="navbar-toggler">
                <span class="navbar-toggler-bar bar1"></span>
                <span class="navbar-toggler-bar bar2"></span>
                <span class="navbar-toggler-bar bar3"></span>
              </button>
            </div>
              <div>
                <a class="navbar-brand" href="javascript:void(0)">
                  <h2><i class="tim-icons icon-atom"></i> Machine Learning</h2>
                </a>
              </div>
          </div>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navigation" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-bar navbar-kebab"></span>
            <span class="navbar-toggler-bar navbar-kebab"></span>
            <span class="navbar-toggler-bar navbar-kebab"></span>
          </button>
          <div class="collapse navbar-collapse" id="navigation">
            <ul class="navbar-nav ml-auto">
              <li class="separator d-lg-none"></li>
            </ul>
          </div>
        </div>
      </nav>
      <div class="modal modal-search fade" id="searchModal" tabindex="-1" role="dialog" aria-labelledby="searchModal" aria-hidden="true">
        <div class="modal-dialog" role="document">
          <div class="modal-content">
            <div class="modal-header">
              <input type="text" class="form-control" id="inlineFormInputGroup" placeholder="SEARCH">
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <i class="tim-icons icon-simple-remove"></i>
              </button>
            </div>
          </div>
        </div>
      </div>
<!-- End Navbar -->
      <div class="content">
        <div class="row">
          <div class="col-lg-8 ml-auto mr-auto">
            <div class="row">
              <div class="col-md-4">
                <button type="button" class="btn btn-block" onclick="location.href='./machine_learning.html'" role="button">
                  Overview
                </button>
              </div>
              <div class="col-md-4">
                <button type="button" class="btn btn-block" onclick="location.href='./logistic_regression.html'" role="button">
                  Logistic Regression
                </button>
              </div>
              <div class="col-md-4">
                <button type="button" class="btn btn-block" onclick="location.href='./ensemble_learners.html'" role="button">
                  Ensemble Learners
                </button>
              </div>
              <div class="col-md-4">
                <button type="button" class="btn btn-block" onclick="location.href='./pyspark_nlp.html'" role="button">
                  PySpark NLP
                </button>
              </div>
              <div class="col-md-4">
                <button type="button" class="btn btn-block" onclick="location.href='./deeplearning_nlp.html'" role="button">
                  Deep Learning NLP
                </button>
              </div>
              <div class="col-md-4">
                <button type="button" class="btn btn-block" onclick="location.href='./the_future.html'" role="button">
                  The Future...
                </button>
              </div>
            </div>
          </div>
        </div>
        <div class="row" >
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h1> Logistic Regression </h1>
              </div>
            </div>
          </div>
        </div> 
        <div class="row" >
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h2> Overview </h2>
                <p> Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression).</p>
                <p> Source:<a href="https://en.wikipedia.org/wiki/Logistic_regression" target="_blank"> Wikipedia</a></p>
                <p> A common problem in classification algorithms are class imbalances. Class imbalance refers to a situation in which the existing classes in a dataset aren't equally represented (i.e. when one class is much larger than the other class).</p>
                <p> Source:<a href="https://bootcampspot.instructure.com/courses/193/pages/17-dot-10-dot-1-oversampling?module_item_id=102452" target="_blank"> UTOR Bootcamp</a></p>
              </div>
            </div>
          </div>
        </div> 
        <div class="row">
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h3> Explanation of Model Choice </h3>
                <p> One of the objectives of the machine learning portion of our project was to predict if hotel reviews provided by customers would either be "positive" or "negative".  We accomplished this by employing different techniques to build and evaluate algorithms/models using resampling.  Afterwards, we compared the predictions/balanced accuracy scores from the various models with each other.  The chosen data from our dataset was first tested with a Simple Logistic Regression algorithm to determine our "first" balanced accuracy score.  This score was then used as a "baseline" to compare with the balanced accuracy scores from the other algorithms.</p>
                <h4> Initial Steps </h4>
                <p> Prior to running our Simple Logistic Regression algorithm (or any algorithm for that matter), we had to take the folloing steps:<ul>
                <li> Create an empty Review_Class column in our data table. </li>
                <li> Fill the Review_Class column with either "positive" or "negative" classifications.  (Note: Reviewer_Score column values greater than or equal to 5.0 were coded/classified as "positive" and Reviewer_Score column values less than or equal to 4.9 were coded/classified as "negative") </li>
                <li> Using label encoding code, label all positive and negative classifications into float values (0 or 1) by converting the string values. </li>
                <li> Using label encoding code, label all Country classifications into float values (0-5) by converting the string values. </li>
                <li> Identify the target variable (Review_Class). </li>
                <li> Disgard all irrelevant columns in our dataset for our machine learning models.  In addition to the Review_Class and Country columns, Average_Score, Review_Total_Negative_Word_Counts, and Review_Total_Positive_Word_Counts were also included in our various machine learning models. </li>
                </ul>
                <h4> Reasoning </h4>
                <p> After converting our positive and negative labels into float values (0 for negative, 1 for positive), we saw a class imbalance of 22,144 0-values and 490,326 1-values.  This class imbalance necessitated the use of the machine learning models seen below. </p>
              </div>
            </div>
          </div>
        </div>
        <div class="row" >
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h2> Simple Logistic Regression Results </h2>
                <h3> Logistic Regression </h3>
                <p> In Logistic Regression, the model analyzes the available data and when presented with a new sample, mathematically determines its probability of belonging to a class. </p>
                <p> Source:<a href="https://bootcampspot.instructure.com/courses/193/pages/17-dot-3-1-overview-of-logistic-regression?module_item_id=102408" target="_blank"> UTOR Bootcamp</a></p>
                <ul>  
                  <li> Simple Logistic Regression Results:<ul>
                  <li> Balanced Accuracy Score = 0.957</li>
                  <p> Source:<a href="https://github.com/JagpreetBath/European_Hotel_Analysis/blob/main/MachineLearning/ML_Supervised/ML_Simple_Logistic_Regression.ipynb" target="_blank"> Repo Link</a></p>
                  </ul>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="row" >
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h2> Class Inbalance Strategies/Results </h2>
                <h3> 1. Oversampling </h3>
                <p> Oversampling: Oversampling occurs if one class has too few instances in the training set.  We would then choose more instances from that class for training until it's larger. Two methods of oversampling used for this project are listed below. </p>
                <p> In Random Oversampling, instances of the minority class are randomly selected and added to the training set until the majority and minority classes are balanced. </p>
                <p> In SMOTE, like random oversampling, the size of the minority is increased. The difference between the two lies in how the minority class is increased in size.  Unlike Random Oversampling, new instances are interpolated in SMOTE. </p>
                <p> Source:<a href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis" target="_blank"> Wikipedia</a></p>
                <p> Source:<a href="https://bootcampspot.instructure.com/courses/193/pages/17-dot-10-dot-1-oversampling?module_item_id=102452" target="_blank"> UTOR Bootcamp</a></p>
                <ul>
                  <li> Native Random Oversampling Results:<ul>
                  <li> Result: Balanced Accuracy Score = 0.770</li>
                  <p> Source:<a href="https://github.com/JagpreetBath/European_Hotel_Analysis/blob/main/MachineLearning/ML_Supervised/ML_Random_Oversampling.ipynb" target="_blank"> Repo Link</a></p>
                  </ul>
                  <li> SMOTE Oversampling Results:<ul>
                  <li> Balanced Accuracy Score = 0.769</li>
                  <p> Source:<a href="https://github.com/JagpreetBath/European_Hotel_Analysis/blob/main/MachineLearning/ML_Supervised/ML_SMOTE_Oversampling.ipynb" target="_blank"> Repo Link</a></p>
                  </ul>
                </ul>
                <h3> 2. Undersampling </h3>
                <p> Undersampling: Undersampling takes the opposite approach of oversampling. Instead of increasing the number of the minority class, the size of the majority class is decreased. For this project, the only method of undersampling used was Random Undersampling. Another method of undersampling called Cluster Centroid Undersampling was attempted, but due to time constraints was not included in our final report. </p>
                <p> In Random Undersampling, randomly selected instances from the majority class are removed until the size of the majority class is reduced, typically to that of the minority class. </p>
                <p> Source:<a href="https://bootcampspot.instructure.com/courses/193/pages/17-dot-10-dot-2-undersampling?module_item_id=102454" target="_blank"> UTOR Bootcamp</a></p>
                <p> Source:<a href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis" target="_blank"> Wikipedia</a></p>
                <ul>  
                  <li> Random Undersampling Results:<ul>
                  <li> Balanced Accuracy Score = 0.770</li>
                  <p> Source:<a href="https://github.com/JagpreetBath/European_Hotel_Analysis/blob/main/MachineLearning/ML_Supervised/ML_Random_Undersampling.ipynb" target="_blank"> Repo Link</a></p>
                  </ul>
                </ul>
                <h3> 3. Combination Sampling </h3>
                <p> Combination Sampling: These algorithms combines aspects of both, oversampling and undersampling.   For this project, we used the SMOTEENN algorithm as our combination sampling method.  SMOTEENN combines the SMOTE and Edited Nearest Neighbors (ENN) algorithms. </p>
                <p> Source:<a href="https://bootcampspot.instructure.com/courses/193/pages/17-dot-10-dot-3-combination-sampling-with-smoteenn?module_item_id=102456" target="_blank"> UTOR Bootcamp</a></p>
                <ul>
                  <li> SMOTEENN (SMOTE and Edited Nearest Neighbors) Results:<ul>
                  <li> Balanced Accuracy Score = 0.773</li>
                  <p> Source:<a href="https://github.com/JagpreetBath/European_Hotel_Analysis/blob/main/MachineLearning/ML_Supervised/ML_Combination_Sampling_With_SMOTEEN.ipynb" target="_blank"> Repo Link</a></p>
                  </ul>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h3> Model Limitations and Benefits </h3>
                <p> As mentioned earlier, one problem in Logistic Regression algorithms are class imbalances. Although oversampling and undersampling help with this issue, they also present other issues themselves. </p>
                <p> A downside of oversampling is its reliance on the immediate neighbors of a data point. Because the algorithm doesn't see the overall distribution of data, the new data points it creates can be heavily influenced by outliers. This can lead to noisy data. With undersampling, the downsides are that it involves loss of data and is not an option when the dataset is small. </p>
                <p> Source:<a href="https://bootcampspot.instructure.com/courses/193/pages/17-dot-10-dot-3-combination-sampling-with-smoteenn?module_item_id=102456" target="_blank"> UTOR Bootcamp</a></p>
              </div>
            </div>
          </div>
        </div> 
        <div class="row" >
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h3> General Coding For Logistic Regression and Resampling </h3>
                <h4> Step 1: Reading our Dataset from our hotel_combined.csv file </h4>
                <ul>
                  <li> Data contains 512470 rows × 21 columns </li>
                </ul>
                <ul>
                    <ul><code>data = Path('../ML_Supervised/hotel_combined.csv')</code></ul>
                    <ul><code>df = pd.read_csv(data)</code></ul>
                    <ul><code>df.head()</code></ul>
                </ul>

                <h4> Step 2: Creating a temporary empty column called Review Class at the end of our Dataset. </h4>
                <ul>
                  <ul><code>df["Review_Class"] = ""</code></ul>
                  <ul><code>df</code></ul>
                </ul>
                
                <h4> Step 3: Labelling Reviewer_Scores either Positive or Negative.</h4>
                <ul>
                  <ul><code>df.loc[df["Reviewer_Score"] <= 4.9, "Review_Class"] = "negative"</code></ul>
                  <ul><code>df.loc[df["Reviewer_Score"] >= 5.0, "Review_Class"] = "positive"</code></ul>
                  <ul><code>df.head()</code></ul>
                </ul>
              
                <h4> Step 4: Using the LabelEncoder to turn the labels in the Review_Class column into numbers.</h4>
                <ul>
                  <ul><code>from sklearn.preprocessing import LabelEncoder</code></ul>
                  <ul><code>le = LabelEncoder()</code></ul>  
                  <ul><code>df2 = df.copy()</code></ul>
                  <ul><code>df2['Review_Class'] = le.fit_transform(df2['Review_Class'])</code></ul>
                </ul>
 
                <h4>Step 5: Using the LabelEncoder to turn the labels in the Country column into numbers.</h4>
                <ul>
                  <ul><code>from sklearn.preprocessing import LabelEncoder</code></ul>
                  <ul><code>le = LabelEncoder()</code></ul>  
                  <ul><code>df3 = df2.copy()</code></ul>
                  <ul><code>df3['Country'] = le.fit_transform(df3['Country'])</code></ul>
                  <ul><code>df3.head()</code></ul>
                </ul>
              
                <h4>Step 6: Checking the balance of our target values.  There is a significant inbalance in the direction of the positive reviews.</h4>
                <ul>
                  <ul><code>df3['Review_Class'].value_counts()</code></ul>
                </ul>
                
                <h4>Step 7: Defining our target variable ('Review_Class') and excluding unecessary columns in our Machine Learning Model.</h4>
                <ul>
                  <ul><code>x_cols = [i for i in df.columns if i not in ('Review_Id', 'Hotel_Address', 'Additional_Number_of_Scoring',</code></ul>
                  <ul><code>'Review_Date', 'Hotel_Name', 'Reviewer_Nationality', 'Negative_Review',</code></ul>  
                  <ul><code>'Total_Number_of_Reviews', 'Total_Number_of_Reviews_Reviewer_Has_Given',</code></ul>
                  <ul><code>'Reviewer_Score', 'Tags', 'days_since_review', 'City',</code></ul>
                  <ul><code>'Positive_Review', 'Review_Class')]</code></ul>
                  <ul><code>X = df3[x_cols]</code></ul>
                  <ul><code>y = df3['Review_Class']</code></ul>
                </ul>

                <h4>Step 8: Splitting our data into testing and training sets.</h4>
                <ul>
                  <ul><code>from sklearn.model_selection import train_test_split</code></ul>
                  <ul><code>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)</code></ul>  
                </ul>

                <h4>Step 9: Resampling the training data with our machine learning model of choice (RandomOversampler in this case).</h4>
                <ul>
                  <ul><code>from imblearn.over_sampling import RandomOverSampler</code></ul>
                  <ul><code>ros = RandomOverSampler(random_state=1)</code></ul>
                  <ul><code>X_resampled, y_resampled = ros.fit_resample(X_train, y_train)</code></ul>
                  <ul><code>Counter(y_resampled)</code></ul>
                </ul>

                <h4>Step 10: Training the Logistic Regression model using the resampled data.</h4>
                <ul>
                  <ul><code>from sklearn.linear_model import LogisticRegression</code></ul>
                  <ul><code>model = LogisticRegression(solver='lbfgs', random_state=1)</code></ul>
                  <ul><code>model.fit(X_resampled, y_resampled)</code></ul>
                </ul>

                <h4>Step 11: Calculating the balanced accuracy score.</h4>
                <ul>
                  <ul><code>from sklearn.metrics import balanced_accuracy_score</code></ul>
                  <ul><code>y_pred = model.predict(X_test)</code></ul>
                  <ul><code>balanced_accuracy_score(y_test, y_pred)</code></ul>
                </ul>

                <h4>Step 12: Displaying the confusion matrix.</h4>
                <ul>
                  <ul><code>from sklearn.metrics import confusion_matrix</code></ul>
                  <ul><code>confusion_matrix(y_test, y_pred)</code></ul>
                </ul>

                <h4>Step 13: Printing the imbalanced classification report.</h4>
                <ul>
                  <ul><code>from imblearn.metrics import classification_report_imbalanced</code></ul>
                  <ul><code>print(classification_report_imbalanced(y_test, y_pred))</code></ul>
                </ul>
              </div>
            </div>
          </div>
        </div>
        <div class="row">
          <div class="col-12">
            <div class="card card-chart">
              <div class="card-header ">
                <h3> Logistic Regression Summary/Recommendations </h3>
                <p> To summarize, Simple Logistic Regression, Oversampling, Undersampling, and SMOTEENN are used to address class imbalance scenarios.  In our European Hotel Analysis, class imbalances refer to positive and negative hotel reviews.  Judging by the reviews in our original dataset, there are a far greater number of positive reviews over negative ones.</p>
                <p> Initially, only the Review_Class and Country columns were included in the various machine learning models.  The balanced accuracy scores for this round of testing was between 0.51 and 0.53.  The Average_Score, Review_Total_Negative_Word_Counts, and Review_Total_Positive_Word_Counts columns were then added/included into our various machine learning models, and the balanced accuracy scores for this second round of testing improved dramatically.  The scores ranged from (0.77 to 0.96). </p>
                <p> Including a customers average score, as well as their positive and negative word counts provided the machine learning algorithms/models more data in order to make predictions on whether future reviews would be positive or negative.</p>
                <p> If the company wants to have the review results for the best logistic regression category (positive or negative) based solely on the balanced accuracy score, then Simple Logistic Regression is recommended based on it's accuracy score of 0.957.</p>
              </div>
            </div>
          </div>
        </div>  
  <div class="fixed-plugin">
    <div class="dropdown show-dropdown">
      <a href="#" data-toggle="dropdown">
        <i class="fa fa-cog fa-2x"> </i>
      </a>
      <ul class="dropdown-menu">
        <li class="header-title"> Sidebar Background</li>
        <li class="adjustments-line">
          <a href="javascript:void(0)" class="switch-trigger background-color">
            <div class="badge-colors text-center">
              <span class="badge filter badge-primary active" data-color="primary"></span>
              <span class="badge filter badge-info" data-color="blue"></span>
              <span class="badge filter badge-success" data-color="green"></span>
            </div>
            <div class="clearfix"></div>
          </a>
        </li>
        <li class="adjustments-line text-center color-change">
          <span class="color-label">LIGHT MODE</span>
          <span class="badge light-badge mr-2"></span>
          <span class="badge dark-badge ml-2"></span>
          <span class="color-label">DARK MODE</span>
        </li>
      </ul>
    </div>
  </div>
  <!--   Core JS Files   -->
  <script src="./assets/js/core/jquery.min.js"></script>
  <script src="./assets/js/core/popper.min.js"></script>
  <script src="./assets/js/core/bootstrap.min.js"></script>
  <script src="./assets/js/plugins/perfect-scrollbar.jquery.min.js"></script>
  <script src="./assets/js/black-dashboard.min.js?v=1.0.0"></script>
  <script>
    $(document).ready(function() {
      $().ready(function() {
        $sidebar = $('.sidebar');
        $navbar = $('.navbar');
        $main_panel = $('.main-panel');

        $full_page = $('.full-page');

        $sidebar_responsive = $('body > .navbar-collapse');
        sidebar_mini_active = true;
        white_color = false;

        window_width = $(window).width();

        fixed_plugin_open = $('.sidebar .sidebar-wrapper .nav li.active a p').html();



        $('.fixed-plugin a').click(function(event) {
          if ($(this).hasClass('switch-trigger')) {
            if (event.stopPropagation) {
              event.stopPropagation();
            } else if (window.event) {
              window.event.cancelBubble = true;
            }
          }
        });

        $('.fixed-plugin .background-color span').click(function() {
          $(this).siblings().removeClass('active');
          $(this).addClass('active');

          var new_color = $(this).data('color');

          if ($sidebar.length != 0) {
            $sidebar.attr('data', new_color);
          }

          if ($main_panel.length != 0) {
            $main_panel.attr('data', new_color);
          }

          if ($full_page.length != 0) {
            $full_page.attr('filter-color', new_color);
          }

          if ($sidebar_responsive.length != 0) {
            $sidebar_responsive.attr('data', new_color);
          }
        });

        $('.switch-sidebar-mini input').on("switchChange.bootstrapSwitch", function() {
          var $btn = $(this);

          if (sidebar_mini_active == true) {
            $('body').removeClass('sidebar-mini');
            sidebar_mini_active = false;
            blackDashboard.showSidebarMessage('Sidebar mini deactivated...');
          } else {
            $('body').addClass('sidebar-mini');
            sidebar_mini_active = true;
            blackDashboard.showSidebarMessage('Sidebar mini activated...');
          }

          // we simulate the window Resize so the charts will get updated in realtime.
          var simulateWindowResize = setInterval(function() {
            window.dispatchEvent(new Event('resize'));
          }, 180);

          // we stop the simulation of Window Resize after the animations are completed
          setTimeout(function() {
            clearInterval(simulateWindowResize);
          }, 1000);
        });

        $('.switch-change-color input').on("switchChange.bootstrapSwitch", function() {
          var $btn = $(this);

          if (white_color == true) {

            $('body').addClass('change-background');
            setTimeout(function() {
              $('body').removeClass('change-background');
              $('body').removeClass('white-content');
            }, 900);
            white_color = false;
          } else {

            $('body').addClass('change-background');
            setTimeout(function() {
              $('body').removeClass('change-background');
              $('body').addClass('white-content');
            }, 900);

            white_color = true;
          }


        });

        $('.light-badge').click(function() {
          $('body').addClass('white-content');
        });

        $('.dark-badge').click(function() {
          $('body').removeClass('white-content');
        });
      });
    });
  </script>
  <script src="https://cdn.trackjs.com/agent/v3/latest/t.js"></script>
  <script>
    window.TrackJS &&
      TrackJS.install({
        token: "ee6fab19c5a04ac1a32a645abde4613a",
        application: "black-dashboard-free"
      });
  </script>
</body>

</html>